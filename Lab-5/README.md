# ğŸ§  Customer Churn Prediction using Neural Networks

## ğŸ“Œ Proje AmacÄ±
Bu proje, bir bankanÄ±n mÃ¼ÅŸteri verileriyle mÃ¼ÅŸteri kaybÄ±nÄ± (churn) tahmin etmeye yÃ¶nelik bir sÄ±nÄ±flandÄ±rma problemidir. FarklÄ± aktivasyon fonksiyonlarÄ±yla Ã§alÄ±ÅŸan MLP modelleri (hem Scikit-learn tabanlÄ± hem de custom sinir aÄŸÄ± mimarisi) karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Performans deÄŸerlendirmesi iÃ§in ÅŸu metrikler kullanÄ±lmÄ±ÅŸtÄ±r:

- Accuracy
- Log Loss
- Precision
- Recall
- F1-Score
- Confusion Matrix

---

## ğŸ“Š Veri KÃ¼mesi Ã–zeti

- **GÃ¶zlem sayÄ±sÄ±:** 10.000
- **Hedef deÄŸiÅŸken:** `Exited` (1: AyrÄ±ldÄ±, 0: KaldÄ±)

### ğŸ¯ SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:
- `Exited = 0 (KalÄ±cÄ±)`: 7.963 (%79.63)
- `Exited = 1 (AyrÄ±lan)`: 2.037 (%20.37)

> **Not:** Veri seti dengesiz olduÄŸundan dolayÄ± accuracy yerine recall, precision ve F1-score daha anlamlÄ±dÄ±r.

### ğŸ” Veri KÃ¼mesinin Ä°lk 5 SatÄ±rÄ±

| RowNumber | CustomerId | Surname  | CreditScore | Geography | Gender | Age | Tenure | Balance   | NumOfProducts | HasCrCard | IsActiveMember | EstimatedSalary | Exited |
|-----------|------------|----------|-------------|-----------|--------|-----|--------|-----------|----------------|-----------|----------------|------------------|--------|
| 1         | 15634602   | Hargrave | 619         | France    | Female | 42  | 2      | 0.00      | 1              | 1         | 1              | 101348.88        | 1      |
| 2         | 15647311   | Hill     | 608         | Spain     | Female | 41  | 1      | 83807.86  | 1              | 0         | 1              | 112542.58        | 0      |
| 3         | 15619304   | Onio     | 502         | France    | Female | 42  | 8      | 159660.80 | 3              | 1         | 0              | 113931.57        | 1      |
| 4         | 15701354   | Boni     | 699         | France    | Female | 39  | 1      | 0.00      | 2              | 0         | 0              | 93826.63         | 0      |
| 5         | 15737888   | Mitchell | 850         | Spain     | Female | 43  | 2      | 125510.82 | 1              | 1         | 1              | 79084.10         | 0      |

---

## âš™ï¸ Veri Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

- `RowNumber`, `CustomerId`, `Surname` sÃ¼tunlarÄ± kaldÄ±rÄ±ldÄ±.
- `Gender`, `Geography`: `LabelEncoder` ile sayÄ±sallaÅŸtÄ±rÄ±ldÄ±.
- SayÄ±sal sÃ¼tunlar: `StandardScaler` ile normalize edildi.
- %80 / %20 eÄŸitim/test ayrÄ±mÄ± stratified olarak yapÄ±ldÄ±.

---

## ğŸ”§ 1. Scikit-learn `MLPClassifier` SonuÃ§larÄ±

- **Model yapÄ±sÄ±:** 2 gizli katman (64, 32)
- **Optimizasyon:** Adam, `max_iter=500`, `early_stopping=True`
- **Ã‡Ä±kÄ±ÅŸ aktivasyonu:** `logistic` (sigmoid)

| Aktivasyon | Accuracy | F1-Score | Log Loss | EÄŸitim SÃ¼resi (sn) |
|------------|----------|----------|----------|---------------------|
| Tanh       | 0.8595   | 0.6003   | 0.3428   | 4.52                |
| Logistic   | 0.8590   | 0.5621   | 0.3440   | 14.68               |
| ReLU       | 0.8555   | 0.5601   | 0.3498   | 2.55                |

### ğŸ” GÃ¶zlemler:

- Tanh ile en yÃ¼ksek F1-score ve en dÃ¼ÅŸÃ¼k log loss elde edilmiÅŸtir.
- EÄŸitim sÃ¼resi aÃ§Ä±sÄ±ndan ReLU Ã§ok hÄ±zlÄ± ancak F1 dÃ¼ÅŸÃ¼ktÃ¼r.
- Logistic iyi precision verse de recall dÃ¼ÅŸÃ¼ktÃ¼r (mÃ¼ÅŸteri kaybÄ±nÄ± kaÃ§Ä±rabilir!).

### ğŸ“‹ Tanh Aktivasyonu DetaylarÄ±:

- **Accuracy:** 0.8595
- **Precision:** 0.7128
- **Recall:** 0.5184
- **F1-Score:** 0.6003

#### Confusion Matrix:

[[1508 85]
[ 196 211]]


> **Yorum:** Pozitif sÄ±nÄ±f (Exited) iyi yakalanmakta; yanlÄ±ÅŸ negatif (196) hÃ¢lÃ¢ var ama genel F1 tatmin edici.

---

## ğŸ§± 2. Custom Neural Network SonuÃ§larÄ±

- **YapÄ±:** 2 gizli katman
- **Epoch sayÄ±sÄ±:** 500
- **Ã‡Ä±kÄ±ÅŸ aktivasyonu:** Sigmoid, **threshold = 0.3** (`default = 0.5` yerine)

| Aktivasyon + Output | Accuracy | F1-Score | EÄŸitim SÃ¼resi (sn) | Final Loss |
|---------------------|----------|----------|---------------------|-------------|
| ReLU + Sigmoid      | 0.822    | 0.5870   | 1.74                | 0.3465      |
| Sigmoid + Sigmoid   | 0.718    | 0.4882   | 3.39                | 0.4363      |
| Tanh + Sigmoid      | 0.8355   | 0.4946   | 8.04                | 0.4071      |

### ğŸ§® Confusion Matrix (Tanh + Sigmoid, threshold = 0.3):

[[1510 97]
[ 232 161]]


### ğŸ“Œ Yorumlar:

- **ReLU + Sigmoid**, hem F1-skorda hem de final lossâ€™ta en iyi sonucu verdi.
- **Sigmoid + Sigmoid**, en kÃ¶tÃ¼ performansa sahip model.
- **Tanh**, accuracyâ€™de Ã¶nde ama recall Ã§ok dÃ¼ÅŸÃ¼k â†’ ayrÄ±lan mÃ¼ÅŸterileri kaÃ§Ä±rma riski.

---

## ğŸ“Œ KarÅŸÄ±laÅŸtÄ±rmalÄ± Yorumlar ve SonuÃ§

| Model                  | Accuracy | Precision | Recall | F1-Score | Log Loss | EÄŸitim SÃ¼resi |
|------------------------|----------|-----------|--------|----------|----------|----------------|
| Scikit-learn (Tanh)    | 0.8595   | 0.7128    | 0.5184 | 0.6003   | 0.3428   | 4.52 s          |
| Scikit-learn (Logistic)| 0.8590   | 0.7637    | 0.4447 | 0.5621   | 0.3440   | 14.68 s         |
| Scikit-learn (ReLU)    | 0.8555   | 0.7360    | 0.4521 | 0.5601   | 0.3498   | 2.55 s          |
| Custom (ReLU+Sigmoid)  | 0.822    | 0.5394    | 0.6438 | 0.5870   | 0.3465   | 1.74 s          |

---

## âœ… Genel DeÄŸerlendirme

- **Recall aÃ§Ä±sÄ±ndan** custom ReLU+Sigmoid modeli, Scikit-learn modellerini geride bÄ±rakÄ±yor â†’ mÃ¼ÅŸteri kaybÄ±nÄ± yakalama aÃ§Ä±sÄ±ndan deÄŸerli.
- **Tanh (Scikit-learn)** modeli ise **dengeli performans** aÃ§Ä±sÄ±ndan en baÅŸarÄ±lÄ± model.
- **EÄŸitim sÃ¼resi** aÃ§Ä±sÄ±ndan custom modeller oldukÃ§a verimli, ancak **hassasiyet (precision)** ve doÄŸrulukta bazÄ± zayÄ±flÄ±klarÄ± var.

---

## âš ï¸ Threshold = 0.3 SeÃ§imi ile:

- Pozitif sÄ±nÄ±fÄ±n daha fazla yakalanmasÄ± (recall â†‘) saÄŸlanÄ±yor,
- Ancak yanlÄ±ÅŸ pozitif (false positive) artabileceÄŸinden precision dÃ¼ÅŸebiliyor.

---

## ğŸ”š SonuÃ§ ve Ã–neriler

Ä°deal model, kullanÄ±m amacÄ±na gÃ¶re deÄŸiÅŸir:

- EÄŸer **mÃ¼ÅŸteri kaybÄ±nÄ± Ã¶nlemek Ã¶ncelikliyse**, recall yÃ¼ksek olan modeller (custom ReLU+Sigmoid) tercih edilebilir.
- EÄŸer **yanlÄ±ÅŸ alarm maliyeti yÃ¼ksekse**, precision yÃ¼ksek modeller (Scikit-learn Logistic) daha uygundur.

### ğŸ”§ Gelecek GeliÅŸtirme Ã–nerileri:

- Veri dengesizliÄŸini dÃ¼zeltmek iÃ§in:
  - SMOTE
  - `class_weights`
  - Focal Loss
- EÄŸitim sÃ¼resi kritikse custom modeller tercih edilebilir; ancak model doÄŸruluÄŸu aÃ§Ä±sÄ±ndan scikit-learn MLP daha kararlÄ± gÃ¶zÃ¼kmektedir.
